{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ec3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1682134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "API = \"01dd6b39-66d5-4ed8-8335-9dd17fe41a3f\"\n",
    "\n",
    "https://www.theguardian.com/technology/artificialintelligenceai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3db5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://content.guardianapis.com/technology/artificialintelligenceai?&api-key=01dd6b39-66d5-4ed8-8335-9dd17fe41a3f&type=article&page=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73a8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ddd166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20916fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695743f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': {'status': 'ok',\n",
       "  'userTier': 'developer',\n",
       "  'total': 1870,\n",
       "  'startIndex': 1,\n",
       "  'pageSize': 10,\n",
       "  'currentPage': 1,\n",
       "  'pages': 187,\n",
       "  'orderBy': 'newest',\n",
       "  'tag': {'id': 'technology/artificialintelligenceai',\n",
       "   'type': 'keyword',\n",
       "   'sectionId': 'technology',\n",
       "   'sectionName': 'Technology',\n",
       "   'webTitle': 'Artificial intelligence (AI)',\n",
       "   'webUrl': 'https://www.theguardian.com/technology/artificialintelligenceai',\n",
       "   'apiUrl': 'https://content.guardianapis.com/technology/artificialintelligenceai'},\n",
       "  'results': [{'id': 'commentisfree/2023/nov/01/rishi-sunaks-ai-safety-britains-brexit-dilemmas-elon-musk',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'commentisfree',\n",
       "    'sectionName': 'Opinion',\n",
       "    'webPublicationDate': '2023-11-01T06:00:33Z',\n",
       "    'webTitle': 'Rishi Sunak’s vanity jamboree on AI safety lays bare the UK’s Brexit dilemmas | Rafael Behr',\n",
       "    'webUrl': 'https://www.theguardian.com/commentisfree/2023/nov/01/rishi-sunaks-ai-safety-britains-brexit-dilemmas-elon-musk',\n",
       "    'apiUrl': 'https://content.guardianapis.com/commentisfree/2023/nov/01/rishi-sunaks-ai-safety-britains-brexit-dilemmas-elon-musk',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/opinion',\n",
       "    'pillarName': 'Opinion'},\n",
       "   {'id': 'technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-11-01T00:01:26Z',\n",
       "    'webTitle': '‘AI’ named most notable word of 2023 by Collins dictionary',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-11-01T00:01:25Z',\n",
       "    'webTitle': 'Nick Clegg compares AI clamour to ‘moral panic’ in 80s over video games',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'science/2023/oct/31/ai-better-than-biopsy-at-assessing-some-cancers-study-finds',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'science',\n",
       "    'sectionName': 'Science',\n",
       "    'webPublicationDate': '2023-10-31T23:30:24Z',\n",
       "    'webTitle': 'AI better than biopsy at assessing some cancers, study finds',\n",
       "    'webUrl': 'https://www.theguardian.com/science/2023/oct/31/ai-better-than-biopsy-at-assessing-some-cancers-study-finds',\n",
       "    'apiUrl': 'https://content.guardianapis.com/science/2023/oct/31/ai-better-than-biopsy-at-assessing-some-cancers-study-finds',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'media/2023/oct/31/microsoft-accused-of-damaging-guardians-reputation-with-ai-generated-poll',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'media',\n",
       "    'sectionName': 'Media',\n",
       "    'webPublicationDate': '2023-10-31T21:17:57Z',\n",
       "    'webTitle': 'Microsoft accused of damaging Guardian’s reputation with AI-generated poll ',\n",
       "    'webUrl': 'https://www.theguardian.com/media/2023/oct/31/microsoft-accused-of-damaging-guardians-reputation-with-ai-generated-poll',\n",
       "    'apiUrl': 'https://content.guardianapis.com/media/2023/oct/31/microsoft-accused-of-damaging-guardians-reputation-with-ai-generated-poll',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-31T13:00:14Z',\n",
       "    'webTitle': 'An AI smoothie shop opened in San Francisco with much hype. Why is it closed already?',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'books/2023/oct/31/publishing-associations-urge-uk-government-to-protect-copyrighted-works-from-ai',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'books',\n",
       "    'sectionName': 'Books',\n",
       "    'webPublicationDate': '2023-10-31T12:40:55Z',\n",
       "    'webTitle': 'Publishing associations urge UK government to protect copyrighted works from AI',\n",
       "    'webUrl': 'https://www.theguardian.com/books/2023/oct/31/publishing-associations-urge-uk-government-to-protect-copyrighted-works-from-ai',\n",
       "    'apiUrl': 'https://content.guardianapis.com/books/2023/oct/31/publishing-associations-urge-uk-government-to-protect-copyrighted-works-from-ai',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/arts',\n",
       "    'pillarName': 'Arts'},\n",
       "   {'id': 'technology/2023/oct/31/educators-teachers-ai-learning-classrooms-misuse',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-31T10:00:39Z',\n",
       "    'webTitle': '‘Is this an appropriate use of AI or not?’: teachers say classrooms are now AI testing labs',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/educators-teachers-ai-learning-classrooms-misuse',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/educators-teachers-ai-learning-classrooms-misuse',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'commentisfree/2023/oct/31/rishi-sunak-ai-safety-summit-tech-challenges',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'commentisfree',\n",
       "    'sectionName': 'Opinion',\n",
       "    'webPublicationDate': '2023-10-31T09:59:59Z',\n",
       "    'webTitle': 'Rishi Sunak’s AI safety summit appears slick – but look closer and alarm bells start ringing  | Chris Stokel-Walker',\n",
       "    'webUrl': 'https://www.theguardian.com/commentisfree/2023/oct/31/rishi-sunak-ai-safety-summit-tech-challenges',\n",
       "    'apiUrl': 'https://content.guardianapis.com/commentisfree/2023/oct/31/rishi-sunak-ai-safety-summit-tech-challenges',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/opinion',\n",
       "    'pillarName': 'Opinion'},\n",
       "   {'id': 'technology/2023/oct/31/uk-ai-summit-tech-regulation',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-31T05:00:35Z',\n",
       "    'webTitle': 'How the UK’s emphasis on apocalyptic AI risk helps business',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/uk-ai-summit-tech-regulation',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/uk-ai-summit-tech-regulation',\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'}],\n",
       "  'leadContent': [{'id': 'technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-11-01T00:01:26Z',\n",
       "    'webTitle': '‘AI’ named most notable word of 2023 by Collins dictionary',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-11-01T00:01:25Z',\n",
       "    'webTitle': 'Nick Clegg compares AI clamour to ‘moral panic’ in 80s over video games',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-31T13:00:14Z',\n",
       "    'webTitle': 'An AI smoothie shop opened in San Francisco with much hype. Why is it closed already?',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/30/no-10-fends-off-claims-rishi-sunak-being-snubbed-over-ai-safety-summit',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-30T20:00:21Z',\n",
       "    'webTitle': 'Elon Musk to attend Rishi Sunak’s AI safety summit in Bletchley Park',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/30/no-10-fends-off-claims-rishi-sunak-being-snubbed-over-ai-safety-summit',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/30/no-10-fends-off-claims-rishi-sunak-being-snubbed-over-ai-safety-summit',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/30/who-is-attending-sunaks-ai-safety-summit-and-what-will-they-discuss',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-30T17:41:48Z',\n",
       "    'webTitle': 'Who is attending Sunak’s AI safety summit – and what will they discuss?',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/30/who-is-attending-sunaks-ai-safety-summit-and-what-will-they-discuss',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/30/who-is-attending-sunaks-ai-safety-summit-and-what-will-they-discuss',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/30/biden-orders-tech-firms-to-share-ai-safety-test-results-with-us-government',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-30T13:35:57Z',\n",
       "    'webTitle': 'Biden hails ‘bold action’ of US government with order on safe use of AI',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/30/biden-orders-tech-firms-to-share-ai-safety-test-results-with-us-government',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/30/biden-orders-tech-firms-to-share-ai-safety-test-results-with-us-government',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/29/ai-doomsday-warnings-a-distraction-from-the-danger-it-already-poses-warns-expert',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-29T08:00:39Z',\n",
       "    'webTitle': 'AI doomsday warnings a distraction from the danger it already poses, warns expert',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/29/ai-doomsday-warnings-a-distraction-from-the-danger-it-already-poses-warns-expert',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/29/ai-doomsday-warnings-a-distraction-from-the-danger-it-already-poses-warns-expert',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/28/artificial-intelligence-origins-turing-to-chatgpt',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-28T11:05:50Z',\n",
       "    'webTitle': 'Race to AI: the origins of artificial intelligence, from Turing to ChatGPT',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/28/artificial-intelligence-origins-turing-to-chatgpt',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/28/artificial-intelligence-origins-turing-to-chatgpt',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/27/no-10-rishi-sunaks-ai-safety-summit-world-leaders',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-27T15:54:51Z',\n",
       "    'webTitle': 'No 10 plays down worries about Sunak’s AI safety summit having few top leaders',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/27/no-10-rishi-sunaks-ai-safety-summit-world-leaders',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/27/no-10-rishi-sunaks-ai-safety-summit-world-leaders',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'},\n",
       "   {'id': 'technology/2023/oct/26/sunak-announces-uk-ai-safety-institute-but-declines-to-support-moratorium',\n",
       "    'type': 'article',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webPublicationDate': '2023-10-26T12:10:18Z',\n",
       "    'webTitle': 'Sunak announces UK AI safety institute but declines to support moratorium',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/2023/oct/26/sunak-announces-uk-ai-safety-institute-but-declines-to-support-moratorium',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/26/sunak-announces-uk-ai-safety-institute-but-declines-to-support-moratorium',\n",
       "    'tags': [],\n",
       "    'references': [],\n",
       "    'isHosted': False,\n",
       "    'pillarId': 'pillar/news',\n",
       "    'pillarName': 'News'}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72876fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theguardian.com/commentisfree/2023/nov/01/rishi-sunaks-ai-safety-britains-brexit-dilemmas-elon-musk\n",
      "\n",
      "\n",
      "https://www.theguardian.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary\n",
      "\n",
      "\n",
      "https://www.theguardian.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games\n",
      "\n",
      "\n",
      "https://www.theguardian.com/science/2023/oct/31/ai-better-than-biopsy-at-assessing-some-cancers-study-finds\n",
      "\n",
      "\n",
      "https://www.theguardian.com/media/2023/oct/31/microsoft-accused-of-damaging-guardians-reputation-with-ai-generated-poll\n",
      "\n",
      "\n",
      "https://www.theguardian.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes\n",
      "\n",
      "\n",
      "https://www.theguardian.com/books/2023/oct/31/publishing-associations-urge-uk-government-to-protect-copyrighted-works-from-ai\n",
      "\n",
      "\n",
      "https://www.theguardian.com/technology/2023/oct/31/educators-teachers-ai-learning-classrooms-misuse\n",
      "\n",
      "\n",
      "https://www.theguardian.com/commentisfree/2023/oct/31/rishi-sunak-ai-safety-summit-tech-challenges\n",
      "\n",
      "\n",
      "https://www.theguardian.com/technology/2023/oct/31/uk-ai-summit-tech-regulation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "web_urls = [item['webUrl'] for item in x['response']['results']]\n",
    "\n",
    "# Print the list of web URLs\n",
    "for url in web_urls:\n",
    "    print(url)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cfad7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a folder with the current date and time format\n",
    "current_datetime = datetime.now()\n",
    "folder_name = current_datetime.strftime('%H_%M_%d_%m_%Y')\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ca4507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: Rishi Sunak’s vanity jamboree on AI safety lays bare the UK’s Brexit dilemmas\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: At a table where democratic accountability should dominate, a diminished nation is trading in Silicon Valley celebrity\n",
      "Paragraph: Who is the more trustworthy custodian of machines capable of diverting the course of human civilisation: Elon Musk or the Chinese Communist party? Will it be the billionaire megalomaniac tycoon who meddles in international crises as if they were video games loaded on to his personal propaganda console? Or the authoritarian superpower that likes digital technology best when it enables more efficient and ruthless social engineering and political repression?\n",
      "Paragraph: Neither is the answer – and thankfully, other options are available. But asking the question in starkly polarised terms illuminates the challenge posed by artificial intelligence that is evolving faster than any effort to bring it under responsible supervision.\n",
      "Paragraph: Everyone can agree that there should be rules because nobody wants awesome computational capability to fall into the wrong hands. But nobody can settle on what the jurisdiction should be, nor agree on how tightly even safe hands should be bound.\n",
      "Paragraph: Rishi Sunak has a plan to make Britain the global hub of tech regulation guided by a world-leading AI safety institute. To assert the UK’s credentials for that role, the prime minister is hosting a two-day international summit at Bletchley Park.\n",
      "Paragraph: Musk will be there. Also, much to Downing Street’s gratification, he will take part in a special dialogue with the prime minister to be broadcast on X, formerly Twitter, summing up the conference conclusions. No such honour is afforded to representatives of the Chinese government, who will also be present, despite objections by hawkish Tory MPs who see Beijing as a hostile power to be contained.\n",
      "Paragraph: Sunak’s view is that China is already a global player in AI, so the dialogue is incomplete without them. Not unreasonably, No 10 will claim the summit as a success if it produces any kind of memorandum that carries Chinese and American signatures.\n",
      "Paragraph: Sunak wanted Joe Biden to come, but has to look grateful that the US vice-president, Kamala Harris, is attending instead. Other notable dignitaries include the European Commission president, Ursula von der Leyen, and UN general secretary, António Guterres. But heads of government are in short supply. Italy’s prime minister will be there, but the president of France and the German chancellor had other plans.\n",
      "Paragraph: There will be enough political muscle and technological expertise in the room to make the event notable as a contribution to global discussion but not, as Sunak had originally hoped, a definitive one.\n",
      "Paragraph: In that respect, the summit reflects Britain’s uneasy post-Brexit strategic position. The prime minister’s grownup diplomacy earns him constructive engagement from international allies, but they haven’t forgotten how his predecessors forfeited their country’s reputation for serious government.\n",
      "Paragraph: Sunak’s contributions to the debate about AI safety will be heard respectfully. His assertion of Britain’s credentials as an intermediary power in the field – behind China and the US, ahead of other European countries – is not a fantasy. The problem comes with the attempt to parlay that position into regulatory leadership. Here, the banal force of Brexit gravity comes into play.\n",
      "Paragraph: Sunak’s instinct is abstinence from hasty, heavy-handed interventions for fear of suffocating enterprise and investment. But even if the UK devises rules that are lighter of touch and smarter than anything conceived in Brussels, the size of the continental single market will still induce tech companies to conform to European norms.\n",
      "Paragraph: The US will do its own thing, as it always does, except when there is a compelling economic or political motive to compromise with jurisdictions of equivalent market heft, which Britain is not.\n",
      "Paragraph: On Monday, before Sunak’s jamboree had even begun, the White House published a sprawling executive order on AI security covering, among other things, consumer protection, data privacy, mandatory sharing of private companies’ safety tests with the federal government and mitigation against discrimination by algorithms. Equivalent European law is in train.\n",
      "Paragraph: The forum where transatlantic consultation and potential alignment happens is the EU-US Trade and Technology Council, from which Britain is excluded.\n",
      "Paragraph: There is also a G7 process, the Hiroshima framework, which is meant to define parameters for safe AI development among the world’s richest democracies. Sunak’s anglocentric ambitions aren’t incompatible with that agenda, but they risk looking otiose and eccentric. There is a whiff of self-aggrandising Brexit exceptionalism – the vision of sovereign Britain as a nimble, autonomous trade superpower – that nobody outside the fringe cult of Conservative Euroscepticism took seriously before the referendum made it government policy.\n",
      "Paragraph: That was a cosy delusion in more benign times. It is dangerously inadequate in the context of cascading global crises, when so many of the certainties and institutional norms of international relations passed down from the 20th century feel dangerously obsolescent.\n",
      "Paragraph: Russia is committed to a violent restoration of Soviet borders. War in the Middle East threatens to spiral outwards into a vast regional conflagration. There is a plausible prospect of Donald Trump returning to the White House next year, and even if he fails, a Republican party moulded in his image cannot be trusted to uphold basic principles of constitutional democracy at home, nor favour them in alliances abroad. This is a world in which strategic freelancing is not an option for Britain, and concerted realignment with old European allies looks inevitable.\n",
      "Paragraph: But that is not a judgment Sunak is equipped to make. His party would never allow it on ideological grounds and, on that score, he represents more continuity with the recent past than is implied by the cultivation of diplomatic pragmatism.\n",
      "Paragraph: While the contrast with Liz Truss and Boris Johnson is undeniable, there is a certain flimsiness about Sunak’s style of governing that is not so far removed from the ways of his predecessors. It is the earnest declaration of intent to be substantial in ways that, on closer examination, never contain actual substance.\n",
      "Paragraph: The planned livestream chat with Musk is a case in point. It implies deference to the glamour of big tech that is inappropriate to the ostensible mission of an AI safety summit. It is trading in Silicon Valley celebrity at a table where democratic accountability should be the dominant currency.\n",
      "Paragraph: There is something about the whole event that feels too conspicuously geared towards engineering a legacy for the prime minister as a man of global standing. Palpable craving for that kind of recognition makes it less available. Leaders do not get to self-certify as international statesmen, and especially not in advance of any achievement.\n",
      "Paragraph: Besides, in the worlds of business and diplomacy there is mounting confidence that Britain is nearing regime change. As the incumbent leader of a G7 country, Sunak can still draw an international crowd. But when it comes to investment of political capital, he is a wasting asset.\n",
      "Paragraph: It must be hard for the prime minister to accept that the greatest service he can perform for his country now is to facilitate the stable transition to a different government, and that his best hope of a creditable write-up in history is to wear his transience with dignified modesty. Of course, he won’t see it that way. He wants to be remembered as a leader with depth and gravitas. And yet he seems unable to cast off the look of a lightweight splashing in the political shallow end.\n",
      "Paragraph: Rafael Behr is a Guardian columnist\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n",
      "Header: ‘AI’ named most notable word of 2023 by Collins dictionary\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: Chosen from a list that includes ‘greedflation’, ‘nepo baby’ and ‘deinfluencing’, use of term has quadrupled this year\n",
      "Paragraph: The technology that is set to dominate the future – for good or ill – is now the word of the year. “AI” has been named the most notable word of 2023 by the dictionary publisher Collins.\n",
      "Paragraph: Defined as “the modelling of human mental functions by computer programs”, AI was chosen because it “has accelerated at such a fast pace and become the dominant conversation of 2023”, the publisher said. The use of the word (strictly an initialism) has quadrupled over the past year.\n",
      "Paragraph: It was chosen from a list of new terms that the publisher said reflect “our ever-evolving language and the concerns of those who use it”. They include “greedflation”, defined as “the use of inflation as an excuse to raise prices to artificially high levels in order to increase corporate profits”, and “debanking”, “the act of depriving a person of banking facilities”.\n",
      "Paragraph: “Nepo baby”, the term used to describe the sons and daughters of celebrities whose careers are assumed to have taken off thanks to their famous parent, and “deinfluencing” made the list. “ “Deinfluencing” is defined by Collins lexicographers as “the use of social media to warn followers to avoid certain commercial products, lifestyle choices, etc”.\n",
      "Paragraph: The annual word of the year is selected by lexicographers monitoring a range of sources, including social media, according to the publisher. Last year’s term was “permacrisis”, while “NFT” was chosen the previous year. Perhaps unsurprisingly, 2020’s word of the year was “lockdown”.\n",
      "Paragraph: Health concerns were prominent in 2023, according to the publisher. “Ultra-processed”, meaning food that is “prepared using complex industrial methods from multiple ingredients, often including ingredients with little or no nutritional value”, is listed, as is “semaglutide”, the appetite-suppressing medication. The use of the term has tripled in the past year.\n",
      "Paragraph: The acronym “Ulez” made the cut – the term meaning ultra-low emissions zone that refers to an area of central London in which more polluting vehicles are restricted.\n",
      "Paragraph: “Bazball”, a style of test cricket in which the batting side plays in a highly aggressive manner, was noted by the dictionary, named after the former New Zealand cricketer and coach, Brendon “Baz” McCullum. The term “canon event”, “an episode that is essential to the formation of an individual’s character or identity”, became popular thanks to the movie Spider-Man: Across the Spider-Verse.\n",
      "Paragraph: Alex Beecroft, the managing director of Collins, said there was “no question” that AI had been “the talking point of 2023”.\n",
      "Paragraph: “We know that AI has been a big focus this year in the way that it has developed and has quickly become as ubiquitous and embedded in our lives as email, streaming or any other once futuristic, now everyday technology.”\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: Nick Clegg compares AI clamour to ‘moral panic’ in 80s over video games\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: Meta executive’s comments show regulation discussions at UK summit could face tough resistance \n",
      "Paragraph: Nick Clegg has compared the clamour over artificial intelligence to the 80s-era “moral panic” over video games, firing a warning shot to international politicians and regulators as they gather for a two-day summit on AI safety.\n",
      "Paragraph: The former UK deputy prime minister who is now president of global affairs at Mark Zuckerberg’s Meta said AI was caught in a “great hype cycle” but warned that new technologies inspired a mixture of excessive zeal and excessive pessimism.\n",
      "Paragraph: British officials are hoping to use the summit, which starts on Wednesday at Bletchley Park, to kickstart a regulatory process that could mirror international attempts to combat the climate crisis. But Clegg’s comments show they are likely to encounter resistance from some of the industry’s most powerful companies.\n",
      "Paragraph: “New technologies always lead to hype,” he said. “They often lead to excessive zeal amongst the advocates and excessive pessimism amongst the critics.\n",
      "Paragraph: “I remember the 80s. There was this moral panic about video games. There were moral panics about radio, the bicycle, the internet.”\n",
      "Paragraph: Referring to predictions that a highly powerful form of AI could emerge within years with revolutionary consequences, he added: “These predictions about what’s going to happen next, what’s going to happen just around the corner, often doesn’t quite turn out as those who are most steeped in it believe.”\n",
      "Paragraph: Clegg is one of the most powerful executives attending the summit this week. Others include Elon Musk, who will use his X social media platform to hold a conversation about regulating AI with Rishi Sunak, the UK prime minister, on Thursday evening.\n",
      "Paragraph: Ursula von der Leyen, the president of the European Commission, will be one of the most high-profile international politicians in attendance. Others including the US president, Joe Biden, and the French president, Emmanuel Macron, have decided to stay away.\n",
      "Paragraph: Some believe the summit should focus on short-term risks, such as biased decision-making and the potential to use AI for election disinformation. Clegg said he wanted delegates to discuss how to watermark AI-made content in a “collaborative way”.\n",
      "Paragraph: But much of the conversation this week will focus on longer-term risks, including the potential for an artificial general intelligence system to evade human control, with many experts warning that a sufficiently advanced system could even pose a threat to humanity itself.\n",
      "Paragraph: Stuart Russell, a professor of computer science at University of California, Berkeley, who is attending the summit, warned on Tuesday the current approach to building AI systems was unsafe.\n",
      "Paragraph: “We need to stop thinking about making AI safe, and start thinking about making safe AI,” he said. “We build the AI and then we have a safety team to stop it from behaving badly – that hasn’t worked and it’s never going to work.”\n",
      "Paragraph: Connor Leahy, the chief executive of the AI safety research company Conjecture, who will also be at the summit, called for an end to allowing privately owned AI companies to build “deadly machines” that he says will take control of the future.\n",
      "Paragraph: He said: “There is nothing more important than people knowing the truth of a small group of unelected, unaccounted, private companies are running a deadly experiment on you and your families, without your consent or your knowledge.”\n",
      "Paragraph: Michelle Donelan, the UK technology secretary, said in advance of the conference: “The risks posed by frontier AI are serious and substantive and it is critical that we work together, both across sectors and countries to recognise these risks.\n",
      "Paragraph: “This summit provides an opportunity for us to ensure we have the right people with the right expertise gathered around the table to discuss how we can mitigate these risks moving forward. Only then will we be able to truly reap the benefits of this transformative technology in a responsible manner.”\n",
      "Paragraph: The UK government is also keen to emphasise the positive potential uses for AI. During the summit ministers will promise to spend £38m to help fund “safe and responsible” AI projects in poorer parts of the world, starting with Africa.\n",
      "Paragraph: Officials say one of the main aims of the summit is to persuade those at the forefront of developing AI technology to slow down their efforts to build the most sophisticated models.\n",
      "Paragraph: However, Clegg’s comments suggest that is likely to be a difficult challenge.\n",
      "Paragraph: “I’m nonetheless still a sufficiently old-fashioned liberal to worry about the dead hand of the state,” he said.\n",
      "Paragraph: “In this area, it is really important to allow innovators, builders – people who are ingenious in the way in which they ultimately entrepreneurially develop these technologies – to do so without immediately assuming that whatever they do next is going to pose some existential risk.”\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n",
      "Header: AI better than biopsy at assessing some cancers, study finds\n",
      "Header: More on this story\n",
      "Header: More on this story\n",
      "Header: US student, 14, wins award for developing soap to treat skin cancer\n",
      "Header: Australian bowel cancer screening age should drop from 50 to 45, medical research authority says\n",
      "Header: Where did I find the courage to talk to my mum about her cancer? At parkrun, far behind the racers\n",
      "Header: Already approved drugs could cut risk of cervical cancer return, study finds\n",
      "Header: Hannah Fry: ‘I’ve become more optimistic as I’ve got older’\n",
      "Header: ‘How did I find the lump? I was masturbating’: Lauren Mahon on sex, breasts and the Big C\n",
      "Header: Exercise is the prescription that every cancer patient deserves – and one they’re in control of\n",
      "Header: New prostate cancer treatment may be ‘on the horizon’, say scientists\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: Researchers in UK say new tool could help ensure patients at high risk are identified promptly\n",
      "Paragraph: Artificial intelligence is almost twice as accurate as a biopsy at judging the aggressiveness of some cancers, according to research that experts say could save the lives of thousands of patients.\n",
      "Paragraph: Cancer kills 10 million people globally every year, according to the World Health Organization. For millions more patients, the disease can be thwarted if detected promptly and dealt with quickly. A key challenge for health workers is to find patients with high-risk tumours and treat them early.\n",
      "Paragraph: A study by the Royal Marsden NHS foundation trust and the Institute of Cancer Research (ICR) found that an AI algorithm was far better than a biopsy at correctly grading the aggressiveness of sarcomas, a rare form of cancer that develops in the body’s connective tissues, such as fat, muscle and nerves.\n",
      "Paragraph: By giving clinicians a more accurate way of grading tumours, researchers hope AI will improve outcomes for patients. Because high-grade tumours can indicate aggressive disease, the new tool could help to ensure those high-risk patients are identified more quickly and treated promptly.\n",
      "Paragraph: Low-risk patients could be spared unnecessary treatments, follow-up scans and hospital visits. Researchers say the algorithm could be applied to other types of the disease in future, potentially benefiting thousands of people. Their findings were published in the Lancet Oncology journal.\n",
      "Paragraph: The team specifically looked at retroperitoneal sarcoma, which develops at the back of the abdomen and is difficult to diagnose and treat due to its location.\n",
      "Paragraph: They used CT scans from 170 Royal Marsden patients with the two most common forms of retroperitoneal sarcoma – leiomyosarcoma and liposarcoma. Using data from the scans, they created an AI algorithm that was then tested on 89 patients in Europe and the US.\n",
      "Paragraph: The technology accurately graded how aggressive the tumour was likely to be 82% of the time, while biopsies were accurate in 44% of cases. AI could also differentiate between leiomyosarcoma and liposarcoma in 84% of sarcomas tested, while radiologists were unable to tell the difference in 35% of cases.\n",
      "Paragraph: The study lead, Christina Messiou, a consultant radiologist at the Royal Marsden and professor in imaging for personalised oncology at the ICR, said: “We’re incredibly excited by the potential of this state-of-the-art technology, which could lead to patients having better outcomes through faster diagnosis and more effectively personalised treatment.\n",
      "Paragraph: “As patients with retroperitoneal sarcoma are routinely scanned with CT, we hope this tool will eventually be used globally, ensuring that not just specialist centres – who see sarcoma patients every day – can reliably identify and grade the disease.”\n",
      "Paragraph: Messiou added: “In the future, this approach may help characterise other types of cancer, not just retroperitoneal sarcoma. Our novel approach used features specific to this disease, but by refining the algorithm, this technology could one day improve the outcomes of thousands of patients each year.”\n",
      "Paragraph: The study was funded by the Royal Marsden Cancer Charity, the National Institute for Health and Care Research (NIHR), the Wellcome Trust and the EORTC Soft Tissue and Bone Sarcoma Group.\n",
      "Paragraph: The Sarcoma UK chief executive, Richard Davidson, said the results “look very promising”. He said: “People are more likely to survive sarcoma if their cancer is diagnosed early – when treatments can be effective and before the sarcoma has spread to other parts of the body. One in six people with sarcoma cancer wait more than a year to receive an accurate diagnosis, so any research that helps patients receive better treatment, care, information and support is welcome.”\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: Microsoft accused of damaging Guardian’s reputation with AI-generated poll \n",
      "Header: More on this story\n",
      "Header: More on this story\n",
      "Header: Today in FocusToday in Focus wins gold award for best news and current affairs podcast\n",
      "Header: Microsoft completes $69bn deal to buy Call of Duty maker Activision Blizzard\n",
      "Header: CMA to investigate UK cloud computing market amid Microsoft and Amazon concerns\n",
      "Header: The Guardian blocks ChatGPT owner OpenAI from trawling its content\n",
      "Header: Russia bans dozens of UK journalists, media figures and politicians\n",
      "Header: UK set to clear Microsoft’s deal to buy Call of Duty maker Activision Blizzard \n",
      "Header: Microsoft submits new Activision Blizzard deal to win over UK regulator \n",
      "Header: Guardian Media Group makes record revenues for news business\n",
      "Header: UK’s CMA to hear more views on Microsoft’s Activision Blizzard deal\n",
      "Header: The Guardian bans all gambling advertising\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: Publisher says poll speculating on cause of woman’s death that appeared next to Guardian article caused ‘significant reputational damage’\n",
      "Paragraph: The Guardian has accused Microsoft of damaging its journalistic reputation by publishing an AI-generated poll speculating on the cause of a woman’s death next to an article by the news publisher.\n",
      "Paragraph: Microsoft’s news aggregation service published the automated poll next to a Guardian story about the death of Lilie James, a 21-year-old water polo coach who was found dead with serious head injuries at a school in Sydney last week.\n",
      "Paragraph: The poll, created by an AI program, asked: “What do you think is the reason behind the woman’s death?” Readers were then asked to choose from three options: murder, accident or suicide.\n",
      "Paragraph: Readers reacted angrily to the poll, which has subsequently been taken down – although highly critical reader comments on the deleted survey were still online as of Tuesday morning.\n",
      "Paragraph: A reader said one of the Guardian reporters bylined on the adjacent story, who had nothing to do with the poll, should be sacked. Another wrote: “This has to be the most pathetic, disgusting poll I’ve ever seen.”\n",
      "Paragraph: The chief executive of the Guardian Media Group, Anna Bateson, outlined her concerns about the AI-generated poll in a letter to Microsoft’s president, Brad Smith.\n",
      "Paragraph: She said the incident was potentially distressing for James’s family and had caused “significant reputational damage” to the organisation as well as damaging the reputation of the journalists who wrote the story.\n",
      "Paragraph: “This is clearly an inappropriate use of genAI [generative AI] by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists,” she wrote.\n",
      "Paragraph: Bateson added that it had demonstrated “the important role that a strong copyright framework plays in enabling publishers to be able to negotiate the terms on which our journalism is used”.\n",
      "Paragraph: Microsoft has a licence with the Guardian to publish the news organisation’s journalism. The Guardian article and accompanying poll appeared on Microsoft Start, a news aggregation website and app.\n",
      "Paragraph: Bateson asked for assurances from Smith that: Microsoft will not apply experimental AI technology on or alongside Guardian journalism without the news publisher’s approval; and Microsoft will always make it clear to users when AI tools are used to create additional units and features next to trusted news brands like the Guardian. Bateson said there was a “strong case” for Microsoft adding a note to the article taking responsibility for the poll.\n",
      "Paragraph: The GMG chief executive added that while this week’s AI safety summit was looking at long-term safety, Microsoft and other platforms needed to outline how they would prioritise trusted information, fair reward for licensing journalism and more transparency and safeguards for consumers around use of AI.\n",
      "Paragraph: A Microsoft spokesperson said: “We have deactivated Microsoft-generated polls for all news articles and we are investigating the cause of the inappropriate content. A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future.”\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n",
      "Header: An AI smoothie shop opened in San Francisco with much hype. Why is it closed already?\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: BetterBlends promised to invest in the city’s beleaguered downtown but closed its doors in under two months\n",
      "Paragraph: In September, a “bespoke AI nutrition” store opened in beleaguered downtown San Francisco to much fanfare, promising smoothie concoctions generated by AI and a much-needed boost to the area. Less than two months later, it has seemingly closed without explanation.\n",
      "Paragraph: BetterBlends advertised “Your Smoothie, powered by AI” and received positive press upon its opening, ginning up excitement for a new business and a novel use of artificial intelligence. Its AI model would take customer orders and preferences to generate a smoothie recipe that would then be blended by hand by co-founders Michael Parlato and Clayton Reynolds, who worked in the shop.\n",
      "Paragraph: But now the storefront sits empty. On Friday 20 October, the locked doors to BetterBlends featured a sign that read “temporarily closed”, stating the shop would reopen in one hour – but sources in the neighborhood said the storefront had been closed for more than three weeks. By the following Monday, the sign had been removed, and the inside of the shop was largely cleared of blenders, fruit, vegetables and other supplies – anything you might need to make a smoothie, with or without AI. Only a trashcan and a few plants remained.\n",
      "Paragraph: The store’s Google Maps listing speaks to both problems in the physical world and its roots in AI. A Google Maps review posted two weeks ago accompanied by a picture of the sign read: “I was hopeful for this business. The owners however did not understand the discipline to run a restaurant. It was often open late and closed early. They changed their hours after a week of being open. And then 1 day they put up a sign, ‘Temporarily closed, be back in an hour.’ They have not been back in over two weeks.” Other reviews were positive, awarding BetterBlends four or five stars. The shop owners themselves uploaded pictures of their smoothies to the Google Maps page as well as an image of happy customers that bears the hallmarks of generative AI. The light on their smiling faces is soft and glossy like a photoshoot. The fruits in the store window are, on closer inspection, unrecognizable blobs of fruit-colored things. The clear plastic cups are branded with gibberish characters that don’t spell anything and filled with lumpy smoothie-ish mixtures. They are cartoonishly large in the customers’ hands, one of which has only three too-long fingers. AI image generators have a documented history of failing to produce text within images or realistic human hands.\n",
      "Paragraph: Much has been said about the ongoing challenges of San Francisco, a city that continues to experience one of the slowest economic recoveries from Covid-19 in the US. BetterBlends was located on Market Street in one of the hardest-hit areas – once a bustling hub of tech offices where foot traffic has slowed to a crawl. The opening of BetterBlends garnered optimism, especially as the boom in artificial intelligence companies has appeared to many as a potential savior for the offices of the flailing city.\n",
      "Paragraph: “People really like the idea of us betting on San Francisco,” co-founder Reynolds said in September, stating that the local response had been “phenomenal”.\n",
      "Paragraph: Christian Cecena, who works at the coffee shop next door, said the “be back in an hour” sign had been affixed to the door for weeks. An employee of a local community outreach group who is stationed on the sidewalk in front of BetterBlends said the longest he saw the business open consecutively was two weeks.\n",
      "Paragraph: “Then that sign went up and we never saw them again,” Cecena said. “It’s just sad because we really need more businesses in this area.”\n",
      "Paragraph: San Francisco still listed BetterBlends in its database of active food service establishment as of 25 October. The company and its co-founders did not respond to repeated requests for comment.\n",
      "Paragraph: BetterBlends’ abrupt apparent closure comes as downtown San Francisco endures  the highest office vacancy rate in its history and the highest retail vacancy rate since 2006. The city has made a concerted effort to revitalize its empty storefronts and sidewalks through new grants and tax breaks targeted at the area BetterBlends briefly called home. San Francisco’s office of economic and workforce development told the Guardian that BetterBlends did not receive any funding from its office.\n",
      "Paragraph: “While the failure of San Francisco’s generative AI blockchain-powered autonomous 5G smoothie bot may be splashy, in no way is it a bellwether for downtown. For a much better indicator, look right across the street, to Ikea’s brand new six-story retail, food and co-working center. Look immediately upstairs from the now-vacant Robo-Blenderia, where empty office space is being converted into 40 apartments,” said Daniel Sider, chief of staff at the San Francisco planning department.\n",
      "Paragraph: Sign up to First Thing\n",
      "Paragraph: Our US morning briefing breaks down the key stories of the day, telling you what’s happening and why it matters\n",
      "Paragraph: after newsletter promotion\n",
      "Paragraph: New retail stores – successful ones – are integral to the recovery of San Francisco, said Stijn Van Nieuwerburgh, the economist behind the much-cited academic paper warning that the city is at risk of entering a “doom loop”. He warned that the artificial intelligence boom has not yet pulled the city out of the woods.\n",
      "Paragraph: “The AI sector is booming and looks like it is leasing at least some of the available office space, which is great,” he said. “[San Francisco] is still a long way from healthy levels of office vacancy, however.”\n",
      "Paragraph: It is unclear what is next for BetterBlends, or whether it ever intended to remain open for longer than a few weeks. Its co-founders previously worked at Local Kitchens, a food technology startup, and said they were seeking $1m in funding to implement BetterBlends’ technology into apps and other businesses. The only visible contact information on the shop’s website was an email address listed under “How to invest” aimed at customers who “would like to contribute to the next generation of dining”.\n",
      "Paragraph: On a Friday morning, as BetterBlends sat empty, more than a dozen people filed in and out of the neighboring coffee shop, where Cecena works. He also sells smoothies – which at $7.50, are priced competitively to the $10 bespoke smoothies of BetterBlends.\n",
      "Paragraph: “I hate to say this, but I did hear that the smoothies weren’t that good,” he said.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: Publishing associations urge UK government to protect copyrighted works from AI\n",
      "Header: More on this story\n",
      "Header: More on this story\n",
      "Header: Who is attending Sunak’s AI safety summit – and what will they discuss?\n",
      "Header: Elon Musk to attend Rishi Sunak’s AI safety summit in Bletchley Park\n",
      "Header: ‘A goldmine at our fingertips’: the promise and perils of AI in Africa\n",
      "Header: Biden hails ‘bold action’ of US government with order on safe use of AI\n",
      "Header: Race to AI: the origins of artificial intelligence, from Turing to ChatGPT\n",
      "Header: No 10 plays down worries about Sunak’s AI safety summit having few top leaders\n",
      "Header: ‘It’s great … except when it’s not’: RishGPT reveals his insights on AI\n",
      "Header: Sunak announces UK AI safety institute but declines to support moratorium\n",
      "Header: Humanity at risk from AI ‘race to the bottom’, says tech expert\n",
      "Header: A day in the life of AI\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: Statement asks government to help stop AI tools ‘using copyright-protected works with impunity’\n",
      "Paragraph: Four leading publishing trade associations have urged the UK government to help end the “unfettered, opaque development” of artificial intelligence tools that use copyright-protected works “with impunity.”\n",
      "Paragraph: The statement, released Tuesday, was co-signed by the Publishers Association, the Society of Authors, the Authors’ Licensing and Collecting Society and the Association of Authors’ Agents. It is the first joint statement from the publishing trade bodies on AI.\n",
      "Paragraph: It comes the day before the government’s AI safety summit, scheduled to take place at Bletchley Park across Wednesday and Thursday. The publishing bodies said they applauded Rishi Sunak for convening the first summit of its kind and for “positioning the UK as a facilitator for strong global action” on AI, but they urged the prime minister to make a “statement of commitment” to protect human creativity, intellectual property, publishing and the creative industries as the technology evolves.\n",
      "Paragraph: “We need acknowledgment of and recompense for the copyright infringement that has already happened […] and assurances that those practices will end,” reads the statement. It named a pirated database of books, Books3, which contains the works of authors such as Zadie Smith and Rachel Cusk and which was used to train AI tools run by companies including Meta and Bloomberg, according to analysis by the Atlantic published in August.\n",
      "Paragraph: Earlier this month, a Bloomberg spokesperson said that the company was not using Books3 to train commercial versions of its large language model BloombergGPT, though it used the dataset to train its research model. In a September lawsuit, Meta said that using copyrighted texts to train its model, LLaMA, is fair use. Shawn Presser, the independent AI developer who originally created Books3, said that while he is sympathetic to authors’ concerns, he made the database so that anyone could develop generative AI tools and worries about the risks of large companies having control of the technology.\n",
      "Paragraph: The publishing bodies said human creativity was the bedrock of the publishing and wider creative industries and was worth about £116bn this year in the UK. They said creative work could only thrive with “a strong copyright regime, compensation, credit for authors and other creators, and rightsholders’ control”.\n",
      "Paragraph: The statement comes after three large European publishing trade bodies – the European Writers’ Council, the Federation of European Publishers and the European and International Booksellers Federation – called on the EU to act on transparency over artificial intelligence for the sake of “the book chain and democracy”.\n",
      "Paragraph: The UK trade bodies said ending the “opaque development” of AI was long overdue and could only be ensured with strong government support. “This is an issue on which the entire publishing industry is united,” they continued. “It is vital that authors and rightsholders are protected by government.\n",
      "Paragraph: “We need practices based on consent and fair payment to ensure that authors and rightsholders are asked for permission and rewarded for the use of their works. We need to ensure that creators are credited when their works are used to generate derivative outputs.”\n",
      "Paragraph: On Monday, Downing Street said it was pleased with the responses it had had to invitations to this week’s AI summit, despite Joe Biden and Emmanuel Macron declining to attend.\n",
      "Paragraph:  This article was amended on 31 October 2023 to add further context regarding Bloomberg, Meta and Shawn Presser that was inadvertently excluded from the original version.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n",
      "Header: ‘Is this an appropriate use of AI or not?’: teachers say classrooms are now AI testing labs\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: Educators are trying to understand how these tools work and, perhaps most pressingly, how they can be misused\n",
      "Paragraph: In the year since OpenAI released ChatGPT, high school teacher Vicki Davis has been rethinking every single assignment she gives her students. Davis, a computer science teacher at Sherwood Christian Academy in Georgia, was well-positioned to be an early adopter of the technology. She’s also the IT director at the school and helped put together an AI policy in March: the school opted to allow the use of AI tools for specific projects so long as students discussed it with their teachers and cited the tool. In Davis’s mind, there were good and bad uses of AI, and ignoring its growing popularity was not going to help students unlock the productive uses or understand its dangers.\n",
      "Paragraph: “It’s actually changed how I design my projects because there are some times I want my students to use AI, and then there are times I don’t want them to,” Davis said. “What am I trying to teach here? Is this an appropriate use of AI or not?”\n",
      "Paragraph: Like teachers across the US and UK, Davis, who also runs the education blog Cool Cat Teacher, spent the summer thinking through what the release of a technology could mean for her.\n",
      "Paragraph: Generative AI can produce images of the pope in a bomber jacket and answer nearly any math problem, so what could it do for students? Educators like her played with the tools and tried to understand how they work, what the utility could be – for teachers and students alike – and, perhaps most pressingly, how the software could be misused. Some took drastic measures, going so far as to abandon homework assignments as long as the technology was accessible.\n",
      "Paragraph: “It feels like we’re in some sort of lab experimenting with our kids because it’s changing so rapidly,” Davis said. “If you had asked me about any of this last fall, I couldn’t have told you any of it because ChatGPT didn’t exist.”\n",
      "Paragraph: In Davis’s senior level class, she prohibited the use of chatbots to code because until recently the College Board, which administers standardized tests like the SAT, didn’t permit AI assistance for programming. (This was recently changed to allow for the use of generative AI as a supplemental tool.) But she has changed an annual project she assigns to incorporate AI into the process. Davis usually asks students to research current models of laptops and evaluate which would be the best fit based on where they want to go to college and what they want to study. Now she asks students to feed the research they have done on their computer options into ChatGPT and ask for a recommendation based on their chosen major and college. The students are then tasked with evaluating ChatGPT’s recommendation. Her goal is to show students how they can use their own knowledge and research on a topic to help them better supervise AI.\n",
      "Paragraph: Teachers who spoke to the Guardian say their primary concern is helping students begin to use AI without enabling cheating. Looming over their futuristic lessons is a fear that an overreliance on these new tools could exacerbate the loss of learning many students suffered during the pandemic. Students had only returned to in-person instruction after two remote years when OpenAI launched ChatGPT, and many were still struggling with the huge hit to their ability to learn or engage in school at all.\n",
      "Paragraph: “There’s so much trauma, and AI can’t help me with that,” said one Maryland high school teacher, Kevin Shindel.\n",
      "Paragraph: After a summer spent experimenting with AI, there’s little consensus among teachers on how to address its use in schools. Many educators in a nearly 370,000-person Facebook group called “ChatGPT for teachers” argue the widespread use of AI chatbots is inevitable and eagerly discuss the best ways to use these tools to make their jobs more efficient and help their students learn. Other teachers the Guardian spoke to suggested student use of the tools be banned until they learn more about the technology behind it.\n",
      "Paragraph: Still, others have focused largely on mitigating any AI-aided cheating; some have stopped assigning homework entirely, opting instead to have their students do supervised work in class. Some teachers have even required students to take handwritten exams or write the first drafts of essays by hand in class to ensure they are coming up with the ideas themselves.\n",
      "Paragraph: But all those the Guardian spoke to agree: regardless of where you land on its use, teachers everywhere are grappling with how to stay on top of constantly evolving generative AI tools.\n",
      "Paragraph: Shindel, a government teacher at a 3,300-student high school in Maryland, has been teaching his students about how AI impacts government and policy for 15 years, but he wasn’t prepared for how quickly people would adopt ChatGPT. He spent the summer learning about and experimenting with various chatbots, and in July presented his findings to the school board in a 38-slide presentation titled “The promise and peril of ChatGPT in today’s classroom”.\n",
      "Paragraph: Shindel gave those in attendance ChatGPT-led activities to experiment with and posed questions about the ethics of its use (“What would a code of ethics for data usage and protection look like?”). Ultimately, he urged the school board to come up with a district-wide policy.\n",
      "Paragraph: “Teachers shouldn’t be responsible for developing classroom policies alone,” Shindel said. “There needs to be some kind of concerted, systemic effort.”\n",
      "Paragraph: Shindel doesn’t believe teachers and policymakers know enough about how chatbots collect student’s personal information – or how to prevent cheating – to allow students to use it. He also worries the tools could exacerbate the lack of student engagement caused by remote learning. Students and teachers are still reeling from the impacts of the pandemic, Shindel said. A recent Harvard graduate school of education study concluded the average public school student between third and eighth grade was half a year behind in math and reading and that nearly all students failed to recover the learning lost after returning to in-person instruction. A 2021 review of 10 studies on pandemic learning loss published by the UK’s Department for Education found that “disadvantaged primary school students were disproportionately behind expectations”, with many students 50% further behind.\n",
      "Paragraph: “I have a couple classes that are almost completely silent. Students don’t interact with each other or answer any questions,” Shindel said.\n",
      "Paragraph: Though they may be in the minority, other schools have made progress establishing AI policies. Little Falls high school in Minnesota decided to ban the use of AI tools entirely in an addendum to the school-wide cheating policy. Davis’s class policy allows certain tools to be used but requires students to seek permission and review the links the AI cites as sources. Kimberly Van Orman, a University of Georgia philosophy professor who is currently teaching a course on the ethics of AI, says she is focusing on transparency. Van Orman requires her students to include the prompt they entered into a chatbot and the response in any assignment they use it for to ensure they don’t “use it in a way that takes the place of learning”.\n",
      "Paragraph: “If you’re trying to understand a concept from the book and you want to kind of talk it over with ChatGPT, that would be fine,” Van Orman said. “Consulting it on your homework problem would not be fine.”\n",
      "Paragraph: Dozens of AI apps targeting students have cropped up in the past few years. Photomath, for instance, predates the current versions of ChatGPT and pitches itself as the No 1 app for math learning. Users can upload a picture of a math problem or equation, and the app will give them the answer with explanations. But several teachers said students began using it during the pandemic to cheat or, at the very least, replace the “productive struggle” that results in learning. Inevitably, students who relied on Photomath during the pandemic struggled when they returned to the classroom, several teachers said.\n",
      "Paragraph: But there are also tools being built to refuse to just give students the answer. Khanmigo, an AI tutor being piloted by educational non-profit Khan Academy, is trained instead to ask questions that nudge students to better understand the material. When the Guardian asked Khanmigo a basic programming question (implement a cache with expirations in Javascript), the chatbot responded: “I can’t provide direct answers or solutions to coding problems.” When the Guardian was asked to solve for z in the equation “3z = 15” and repeatedly responded with “I don’t know”, the AI tutor kept providing guidance on how to solve it until it finally provided four multiple-choice options. Khanmigo was quicker to provide the right answer when the Guardian responded with an incorrect answer twice. ChatGPT, on the other hand, immediately provided the solution in both cases.\n",
      "Paragraph: Sal Khan, the founder of Khan Academy, says the organization spent thousands of hours training the system, which is powered by ChatGPT-4, to understand that it’s not supposed to do people’s work for them. “We said stuff like: ‘You’re a Socratic tutor, you are here to make the students actively learn, not just passively,’” he said.\n",
      "Paragraph: Though it’s still in an experimental phase, these training processes are what distinguishes an AI tutor from an AI cheating tool, Khan argues.\n",
      "Paragraph: “This time next year, you’re going to have 50 [companies] who say that they have an AI tutor,” Khan said. “But probably 90% of them are going to be somewhat shady and they’re just going slap a little bit of a layer on top of ChatGPT-3.5. They’re going to be mainly cheating tools, and not good ones.”\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: Rishi Sunak’s AI safety summit appears slick – but look closer and alarm bells start ringing \n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: The prime minister wants progress on this tech to be his legacy, but in truth he is failing to equip us for the challenges it brings\n",
      "Paragraph: The UK’s AI safety summit opens at Bletchley Park this week, and is the passion project of Rishi Sunak: a prime minister desperate for a good news story as his government looks down the barrel of a crushing election defeat.\n",
      "Paragraph: Sunak appears to want progress on AI to become his lasting legacy. Last week, he delivered a speech about the risks of AI if weaponised by terrorists and cybercriminals, and published a series of documents on “frontier AI”, an industry term for generative AI tools such as ChatGPT and DALL-E. He even unveiled a UK AI safety institute.\n",
      "Paragraph: The message was clear. The slick – albeit very behind in the polls – Stanford MBA grad who likes to holiday in California had, to use a favoured phrase of his, “got to grips” with the problem. The British people, according to Sunak, “should have peace of mind that we’re developing the most advanced protections for AI of any country in the world”.\n",
      "Paragraph: And now the summit. Sunak has lured 100 leading lights from the world of AI to Bletchley Park, including representatives from the world’s biggest tech companies and leaders from across the globe. But – and this is a big but – there are precious few civil society representatives, much to the annoyance of more than 100 signatories of an open letter published on Monday, who have warned the meeting will achieve little with such a narrow guest list.\n",
      "Paragraph: It’s hard to disagree with them. The agenda for the summit goes heavy on the existential risks of a Terminator-style AI gaining super-intelligent sentience. But many of the academics and campaigners who have been studying the space for longer than it has been Sunak’s hobbyhorse, and who will be only watching the livestream because they weren’t invited to the party, say that risk is a strawman designed to distract from the bigger issues inherent with AI.\n",
      "Paragraph: There are more pressing problems, they warn. One is misrepresentation and bias against minorities. Type “doctor” or “CEO” into a generative AI image creator and you’ll be shown a row of middle-aged, white male faces. And with the government saying it wants police forces to integrate surveillance AI into its operations, those issues of representation have real-world ramifications.\n",
      "Paragraph: The other hole in the event’s agenda is AI’s environmental impact, which has a massive drain on our planet’s natural resources. The use of power by AI is likely to eclipse that of many large countries in a matter of years, and yet it is paid only lip service in the discussion paper.\n",
      "Paragraph: The terminology used in the materials to promote the event, with its mention of frontier AI, feels heavily skewed towards the status quo. It echoes the name of the Frontier Model Forum, a talking shop for the tech industry, and a body hastily put together to make it seem like it is self-policing to try to ward off regulation. The use of industry language suggests Sunak will remain supine in the face of big tech’s latest innovation. In many ways, it is no surprise. The prime minister has made no bones about the fact he wants to encourage tech companies to develop AI within the UK, hoping to reap the benefits it can offer the economy. He has also hinted he won’t nag them too much about safety. In fact, Sunak is so keen to buddy up to the tech representatives that he’s hanging out with Musk on X, formerly Twitter, in a livestreamed event after the conclave.\n",
      "Paragraph: I’ve spent the last year speaking to experts in the field for a book on the enormous impact this wave of AI will have on our lives that will be published next year. And in the past month, I have seen UK government representatives boast about the central role Britain will have in regulating the technology in the years to come. I sat in a conference hall in Amsterdam watching Viscount Camrose, the UK minister for AI and intellectual property, call the summit “historic”. Last week I watched a livestream of the deputy prime minister, Oliver Dowden, hyping up the event.\n",
      "Paragraph: But I’ve seen who’s on the tech companies’ side of the table. I’ve seen who’s on the government’s side. And I’ve seen the fierce intelligence of the people who have been left out of the summit, in the cold this November. I’m not holding my breath for positive results and a new AI accord that meets the challenges we face.\n",
      "Paragraph: Chris Stokel-Walker is the author of How AI Ate the World, to be published in May 2024\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n",
      "Header: How the UK’s emphasis on apocalyptic AI risk helps business\n",
      "Header: Most viewed\n",
      "Header: Most viewed\n",
      "Paragraph: Experts say focus of the UK’s global AI summit on ‘frontier AI’ distracts from regulation of existing ills of technology\n",
      "Paragraph: In the spring of 2023, the UK government set out its plans to address the rapidly evolving AI landscape. In a white paper titled “A pro-innovation approach to AI regulation” the secretary of state for science, innovation and technology described the many benefits and opportunities she believed the technology to hold and explained the government’s decision to take a “principles-based approach” to regulating it. In short: the UK didn’t plan to create new legislation, instead opting to clarify existing laws that could apply to AI.\n",
      "Paragraph: “New rigid and onerous legislative requirements on businesses could hold back AI innovation and reduce our ability to respond quickly and in a proportionate way to future technological advances,” the white paper reads.\n",
      "Paragraph: Between the lines of the government’s leaflet, experts say, is a coded message: we want AI companies’ business; we’re not going to regulate AI right now.\n",
      "Paragraph: In the lead-up to the global AI summit the UK is convening in early November, Rishi Sunak has echoed the desire to strengthen the UK’s position as an AI leader, both in terms of innovation and safety oversight. On Thursday he said it was too soon, however, for the government to legislate on AI. Arguing that more scrutiny of advanced models is needed first, he said: “It’s hard to regulate something if you don’t fully understand it.”\n",
      "Paragraph: Experts say much of what Sunak plans to discuss at the summit has been theoretical, due to its focus on so-called “frontier AI” – the term for the most advanced AI models.\n",
      "Paragraph: Documents released ahead of the summit have detailed an array of risks, some of which are more tangible, such as AI-generated disinformation and disruption of the jobs market. The day one agenda also refers to discussions of “election disruption, erosion of social trust and exacerbating global inequalities”.\n",
      "Paragraph: Other threats detailed in these documents include whether AI could allow individuals to create bioweapons or become so powerful that they bypass safety guardrails. The final agenda for the summit, an initial draft of which was obtained by the Guardian, reflects that same focus, arguing the frontier is “where the risks are most urgent” and “where the vast promise of the future economy lies” – a knife-edge between potential and disaster.\n",
      "Paragraph: “We are focusing on frontier AI at the AI Safety Summit because this is the area where we face the most urgent risks from the most dangerous capabilities of advanced AI,” said a spokesperson for the Department for Science, Innovation and Technology. “That isn’t to say the other risks aren’t important and we’re using other international forums and work at a national level to address those.”\n",
      "Paragraph: Few observers expect the meeting to result in firm legislative proposals although Sunak said on Thursday he would push for an AI equivalent of the Intergovernmental Panel on Climate Change – a coalition of experts who could help forge an international consensus on safety.\n",
      "Paragraph: Concerns about existential risk may distract from meaningful regulations that could mitigate the existing ills that AI tools can exacerbate, including the surveillance of marginalized groups, inequity in hiring and housing and the proliferation of misinformation, some experts warn.\n",
      "Paragraph: “Policymaker attention and regulatory efforts are concentrated on a set of capabilities that don’t exist yet, a set of models that don’t yet show those capabilities,” said Michael Birtwistle, the associate director of law and policy at the Ada Lovelace Institute, an AI research organization. “And today’s harms really don’t figure in that calculation.”\n",
      "Paragraph: London is not alone in that approach. Experts say the US, too, has been overly focused on future or hypothetical harms while being slow to install enforceable guardrails on current applications.\n",
      "Paragraph: “And in a practical way, it is not a helpful target for regulation or for governance because it’s a moving target,” Birtwistle said.\n",
      "Paragraph: In its current form, AI powers policing and surveillance tools that have been used to disproportionately target and, at times, misidentify Black and brown people. AI hiring tools have been found to make discriminatory decisions that have implications for who is considered for jobs. The algorithms social platforms are built on have fueled the spread of election misinformation. And there’s little transparency about how these programs work or the data they are trained on.\n",
      "Paragraph: Frontier AI is still in the “idea phase”, said Janet Haven, a member of the US National Artificial Intelligence Advisory Committee (Naiac) and the executive director of the non-profit tech research organization Data & Society, “but there are many AI systems in use which empirical evidence has shown us are already causing harms that are not being addressed by regulation, industry practices or by law”. The summit’s focus on international collaboration is “a missed opportunity”, Haven argued, one that could have been spent discussing new legislation or how the UK could use existing law to address AI.\n",
      "Paragraph: “I think international collaboration of any sort without a national framework of laws and regulations in place is extremely difficult,” she said. “You don’t have a baseline to work from.”\n",
      "Paragraph: In its approach, experts say, the UK has taken some cues from the US, where lawmakers have repeatedly quizzed AI leaders in Congress, the White House has set out voluntary AI safety commitments and Joe Biden on Monday issued an executive order setting up guardrails for the use of advanced AI systems by federal agencies, but meaningful regulation so far has remained elusive.\n",
      "Paragraph: The draft agenda for the UK summit indicated companies would provide an update on how they were adhering to the White House’s voluntary AI safety commitments. Biden’s latest executive order was reportedly timed to precede the UK summit and may prove to be instructive to how the UK thinks about its own legislative approach. Vice-President Kamala Harris is attending the summit in the UK.\n",
      "Paragraph: Harris said on Monday that the US government had a “a moral, ethical and societal duty to make sure AI is adopted and advanced in a way that protects the public from potential harm and ensures that everyone is able to enjoy its benefits”.\n",
      "Paragraph: In both the US and the UK, the leading companies behind AI technology have been an integral part of conversations about how the technology should be regulated. Among those expected to be at the UK global summit are a long list of tech executives in addition to global leaders. In the US, Senator Chuck Schumer has now hosted two closed-door meetings with mostly tech industry representatives. The first, held in September, focused on national security, privacy issues and high-risk AI systems and included Sam Altman, the CEO of OpenAI; Elon Musk; and Sundar Pichai, the CEO of Google, as guests. The second, held on 24 October and focused on innovation, was attended by a mix of tech venture capitalists, investors and a few academics.\n",
      "Paragraph: The summit and these discussions fail to address the “clear and present danger” of AI and give big tech a forum to push for self-regulation and voluntary commitments, say a group of experts who organized a counter-summit on Monday. AI ethicists and critics including Amba Kak, the executive director of the AI Now Institute; Safiya Noble, the founder of the Center on Race & Digital Justice; Maria Ressa, a journalist and member of the Real Facebook Oversight Board, spoke at The People’s Summit for AI Safety, a press conference that would serve as an “antidote” to the UK summit. “The UK government has listened to companies opting for self-regulation,” said Marietje Schaake, a former MEP and the special advisory to the European Commission implementing the Digital Services Act. “The Summit missed out on inviting a wider representation of experts and people impacted by AI-driven disruption.”\n",
      "Paragraph: The disproportionate focus on tech leaders’ perspectives has also allowed for an unhelpful framework on how regulation could affect innovation to take root, said Callie Schroeder, a senior counsel and global privacy counsel at the non-profit Electronic Privacy Information Center.\n",
      "Paragraph: “They still have it a little bit set up in their head that this is a game of privacy and consumer protection versus innovation when it doesn’t have to be confrontational that way,” Schroeder said. “There are absolutely ways to develop innovative new technology while also paying attention to risks.”\n",
      "Paragraph: The spokesperson for the Department of Science, Innovation and Technology said the summit will “bring together a wide array of attendees including international governments, academia, industry and civil society” in an effort to “drive targeted, rapid international action” on the responsible development of AI.\n",
      "Paragraph: Both countries are also motivated in part by a desire to compete on a global scale. For the US, that competition is driven in part by fears that countries like China could move more quickly to develop AI systems that could be used in a way that poses national security threats. In a 6 June letter, Schumer and other lawmakers invited members of Congress to discuss the “extraordinary potential, and risks, AI presents”. The topics included how to maintain US leadership in AI and how the country’s “adversaries” use AI. The Senate select committee on intelligence has since held a hearing on the national security implications of AI that included testimony from Yann LeCun, the vice-president and chief AI scientist at Meta. (China, for its part, has proposed guidelines that would prohibit large language models from producing content that could be seen as critical of the government.)\n",
      "Paragraph: Sunak, who faces a general election next year, has emphasized the UK’s position as an intellectual leader in AI. “You would be hard-pressed to find many other countries other than the US in the western world with more expertise and talent in AI,” Sunak said during a recent visit to Washington DC.\n",
      "Paragraph: When it comes to AI regulation, experts argue the UK is looking to distinguish itself from the EU post-Brexit.\n",
      "Paragraph: “What the UK does on AI to a certain extent, has to respond to what the EU does,” said Oliver Marsh, a project lead at the human rights organization AlgorithmWatch. “If the UK looks at what the EU does and says that’s really sensible, then that is kind of a problem for politicians who want to claim the UK can do things better than the EU.” Simultaneously, any radical deviation by the UK will throw existing scientific collaborations into chaos, according to Marsh. \n",
      "Paragraph: Discussions of the EU’s AI Act, which proposes a risk-based tiered approach to legislating AI, commenced well before the release of ChatGPT. As a result, civil society groups were able to successfully focus legislative attention on existing harms and pushed for language that requires transparency around law enforcement use of “high-risk” AI both in policing and migration control. The EU is in the midst of hammering out some of the final details of the bill after years of development – those involved had a 25 October deadline to finalize how the legislation handles questions of police surveillance and generative AI.\n",
      "Paragraph: But the EU has not been immune to the hype of generative AI, said Sarah Chander, a senior policy analyst at European Digital Rights (EDRi). EU member states are currently pushing back on those transparency proposals around police use of AI and looking to relitigate how to decide what is considered high risk.\n",
      "Paragraph: “We think it’s important to look at the infrastructural, economic and environmental concerns when it comes to general purpose AI, but that hype has directed attention away from [our original priorities], and has allowed member states in the EU to deprioritize the question of the law enforcement,” said Chander.\n",
      "Paragraph: As the EU races to be the first to establish AI regulations, experts continue to push the US and UK to refocus their efforts on creating meaningful legislation that addresses existing AI harms.\n",
      "Paragraph: “The frontier is here,” said Clara Maguire the executive director of the non-profit journalism organization the Citizens. “We are witnessing the weaponization of AI today, enabled by many of the companies with leaders attending Prime Minister Sunak’s summit.”\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "An error occurred: name 'content' is not defined\n"
     ]
    }
   ],
   "source": [
    "def extract_content_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # Extract and print the title and content\n",
    "            title = soup.title.string\n",
    "            for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "                print(\"Header:\", header.text)\n",
    "            for paragraph in soup.find_all('p'):\n",
    "                print(\"Paragraph:\", paragraph.text)\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            if content:\n",
    "                print(\"Title:\", title)\n",
    "                print(\"Content:\", content.text)\n",
    "                print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            else:\n",
    "                print(\"No content found on the page:\", url)\n",
    "        else:\n",
    "            print(\"Failed to retrieve the page:\", url)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Loop through the list of web URLs and extract content\n",
    "for url in web_urls:\n",
    "    extract_content_from_url(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8412b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content from 10 articles have been saved to the folder '12_58_01_11_2023'\n"
     ]
    }
   ],
   "source": [
    "def save_content_to_file(url, folder, filename):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    " \n",
    "            with open(os.path.join(folder, filename), 'w', encoding='utf-8') as file:\n",
    "                for header in soup.find_all(['h1']):\n",
    "                    file.write(\"Tile: \" + header.text + '\\n'*5)\n",
    "                for paragraph in soup.find_all('p'):\n",
    "                    file.write(paragraph.text + '\\n')\n",
    "        else:\n",
    "            print(\"Failed to retrieve the page:\", url)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Loop through the list of web URLs and save content to separate text files\n",
    "for index, url in enumerate(web_urls):\n",
    "    filename = f'article_{index}.txt'  # Create a unique filename for each article\n",
    "    save_content_to_file(url, folder_name, filename)\n",
    "\n",
    "print(\"Executed Perfectly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8422cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a397cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " a\n"
     ]
    }
   ],
   "source": [
    "print(\"abc\",'\\n'*5,\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd4ccaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'response': {'status': 'ok',\n",
       "   'userTier': 'developer',\n",
       "   'total': 1870,\n",
       "   'startIndex': 1,\n",
       "   'pageSize': 10,\n",
       "   'currentPage': 1,\n",
       "   'pages': 187,\n",
       "   'orderBy': 'newest',\n",
       "   'tag': {'id': 'technology/artificialintelligenceai',\n",
       "    'type': 'keyword',\n",
       "    'sectionId': 'technology',\n",
       "    'sectionName': 'Technology',\n",
       "    'webTitle': 'Artificial intelligence (AI)',\n",
       "    'webUrl': 'https://www.theguardian.com/technology/artificialintelligenceai',\n",
       "    'apiUrl': 'https://content.guardianapis.com/technology/artificialintelligenceai'},\n",
       "   'results': [{'id': 'commentisfree/2023/nov/01/rishi-sunaks-ai-safety-britains-brexit-dilemmas-elon-musk',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'commentisfree',\n",
       "     'sectionName': 'Opinion',\n",
       "     'webPublicationDate': '2023-11-01T06:00:33Z',\n",
       "     'webTitle': 'Rishi Sunak’s vanity jamboree on AI safety lays bare the UK’s Brexit dilemmas | Rafael Behr',\n",
       "     'webUrl': 'https://www.theguardian.com/commentisfree/2023/nov/01/rishi-sunaks-ai-safety-britains-brexit-dilemmas-elon-musk',\n",
       "     'apiUrl': 'https://content.guardianapis.com/commentisfree/2023/nov/01/rishi-sunaks-ai-safety-britains-brexit-dilemmas-elon-musk',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/opinion',\n",
       "     'pillarName': 'Opinion'},\n",
       "    {'id': 'technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-11-01T00:01:26Z',\n",
       "     'webTitle': '‘AI’ named most notable word of 2023 by Collins dictionary',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-11-01T00:01:25Z',\n",
       "     'webTitle': 'Nick Clegg compares AI clamour to ‘moral panic’ in 80s over video games',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'science/2023/oct/31/ai-better-than-biopsy-at-assessing-some-cancers-study-finds',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'science',\n",
       "     'sectionName': 'Science',\n",
       "     'webPublicationDate': '2023-10-31T23:30:24Z',\n",
       "     'webTitle': 'AI better than biopsy at assessing some cancers, study finds',\n",
       "     'webUrl': 'https://www.theguardian.com/science/2023/oct/31/ai-better-than-biopsy-at-assessing-some-cancers-study-finds',\n",
       "     'apiUrl': 'https://content.guardianapis.com/science/2023/oct/31/ai-better-than-biopsy-at-assessing-some-cancers-study-finds',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'media/2023/oct/31/microsoft-accused-of-damaging-guardians-reputation-with-ai-generated-poll',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'media',\n",
       "     'sectionName': 'Media',\n",
       "     'webPublicationDate': '2023-10-31T21:17:57Z',\n",
       "     'webTitle': 'Microsoft accused of damaging Guardian’s reputation with AI-generated poll ',\n",
       "     'webUrl': 'https://www.theguardian.com/media/2023/oct/31/microsoft-accused-of-damaging-guardians-reputation-with-ai-generated-poll',\n",
       "     'apiUrl': 'https://content.guardianapis.com/media/2023/oct/31/microsoft-accused-of-damaging-guardians-reputation-with-ai-generated-poll',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-31T13:00:14Z',\n",
       "     'webTitle': 'An AI smoothie shop opened in San Francisco with much hype. Why is it closed already?',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'books/2023/oct/31/publishing-associations-urge-uk-government-to-protect-copyrighted-works-from-ai',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'books',\n",
       "     'sectionName': 'Books',\n",
       "     'webPublicationDate': '2023-10-31T12:40:55Z',\n",
       "     'webTitle': 'Publishing associations urge UK government to protect copyrighted works from AI',\n",
       "     'webUrl': 'https://www.theguardian.com/books/2023/oct/31/publishing-associations-urge-uk-government-to-protect-copyrighted-works-from-ai',\n",
       "     'apiUrl': 'https://content.guardianapis.com/books/2023/oct/31/publishing-associations-urge-uk-government-to-protect-copyrighted-works-from-ai',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/arts',\n",
       "     'pillarName': 'Arts'},\n",
       "    {'id': 'technology/2023/oct/31/educators-teachers-ai-learning-classrooms-misuse',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-31T10:00:39Z',\n",
       "     'webTitle': '‘Is this an appropriate use of AI or not?’: teachers say classrooms are now AI testing labs',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/educators-teachers-ai-learning-classrooms-misuse',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/educators-teachers-ai-learning-classrooms-misuse',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'commentisfree/2023/oct/31/rishi-sunak-ai-safety-summit-tech-challenges',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'commentisfree',\n",
       "     'sectionName': 'Opinion',\n",
       "     'webPublicationDate': '2023-10-31T09:59:59Z',\n",
       "     'webTitle': 'Rishi Sunak’s AI safety summit appears slick – but look closer and alarm bells start ringing  | Chris Stokel-Walker',\n",
       "     'webUrl': 'https://www.theguardian.com/commentisfree/2023/oct/31/rishi-sunak-ai-safety-summit-tech-challenges',\n",
       "     'apiUrl': 'https://content.guardianapis.com/commentisfree/2023/oct/31/rishi-sunak-ai-safety-summit-tech-challenges',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/opinion',\n",
       "     'pillarName': 'Opinion'},\n",
       "    {'id': 'technology/2023/oct/31/uk-ai-summit-tech-regulation',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-31T05:00:35Z',\n",
       "     'webTitle': 'How the UK’s emphasis on apocalyptic AI risk helps business',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/uk-ai-summit-tech-regulation',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/uk-ai-summit-tech-regulation',\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'}],\n",
       "   'leadContent': [{'id': 'technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-11-01T00:01:26Z',\n",
       "     'webTitle': '‘AI’ named most notable word of 2023 by Collins dictionary',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/ai-named-most-notable-word-of-2023-by-collins-dictionary',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-11-01T00:01:25Z',\n",
       "     'webTitle': 'Nick Clegg compares AI clamour to ‘moral panic’ in 80s over video games',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/nov/01/nick-clegg-ai-clamour-similar-moral-panic-video-games',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-31T13:00:14Z',\n",
       "     'webTitle': 'An AI smoothie shop opened in San Francisco with much hype. Why is it closed already?',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/31/ai-smoothie-betterblends-san-francisco-business-closes',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/30/no-10-fends-off-claims-rishi-sunak-being-snubbed-over-ai-safety-summit',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-30T20:00:21Z',\n",
       "     'webTitle': 'Elon Musk to attend Rishi Sunak’s AI safety summit in Bletchley Park',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/30/no-10-fends-off-claims-rishi-sunak-being-snubbed-over-ai-safety-summit',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/30/no-10-fends-off-claims-rishi-sunak-being-snubbed-over-ai-safety-summit',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/30/who-is-attending-sunaks-ai-safety-summit-and-what-will-they-discuss',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-30T17:41:48Z',\n",
       "     'webTitle': 'Who is attending Sunak’s AI safety summit – and what will they discuss?',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/30/who-is-attending-sunaks-ai-safety-summit-and-what-will-they-discuss',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/30/who-is-attending-sunaks-ai-safety-summit-and-what-will-they-discuss',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/30/biden-orders-tech-firms-to-share-ai-safety-test-results-with-us-government',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-30T13:35:57Z',\n",
       "     'webTitle': 'Biden hails ‘bold action’ of US government with order on safe use of AI',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/30/biden-orders-tech-firms-to-share-ai-safety-test-results-with-us-government',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/30/biden-orders-tech-firms-to-share-ai-safety-test-results-with-us-government',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/29/ai-doomsday-warnings-a-distraction-from-the-danger-it-already-poses-warns-expert',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-29T08:00:39Z',\n",
       "     'webTitle': 'AI doomsday warnings a distraction from the danger it already poses, warns expert',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/29/ai-doomsday-warnings-a-distraction-from-the-danger-it-already-poses-warns-expert',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/29/ai-doomsday-warnings-a-distraction-from-the-danger-it-already-poses-warns-expert',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/28/artificial-intelligence-origins-turing-to-chatgpt',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-28T11:05:50Z',\n",
       "     'webTitle': 'Race to AI: the origins of artificial intelligence, from Turing to ChatGPT',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/28/artificial-intelligence-origins-turing-to-chatgpt',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/28/artificial-intelligence-origins-turing-to-chatgpt',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/27/no-10-rishi-sunaks-ai-safety-summit-world-leaders',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-27T15:54:51Z',\n",
       "     'webTitle': 'No 10 plays down worries about Sunak’s AI safety summit having few top leaders',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/27/no-10-rishi-sunaks-ai-safety-summit-world-leaders',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/27/no-10-rishi-sunaks-ai-safety-summit-world-leaders',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'},\n",
       "    {'id': 'technology/2023/oct/26/sunak-announces-uk-ai-safety-institute-but-declines-to-support-moratorium',\n",
       "     'type': 'article',\n",
       "     'sectionId': 'technology',\n",
       "     'sectionName': 'Technology',\n",
       "     'webPublicationDate': '2023-10-26T12:10:18Z',\n",
       "     'webTitle': 'Sunak announces UK AI safety institute but declines to support moratorium',\n",
       "     'webUrl': 'https://www.theguardian.com/technology/2023/oct/26/sunak-announces-uk-ai-safety-institute-but-declines-to-support-moratorium',\n",
       "     'apiUrl': 'https://content.guardianapis.com/technology/2023/oct/26/sunak-announces-uk-ai-safety-institute-but-declines-to-support-moratorium',\n",
       "     'tags': [],\n",
       "     'references': [],\n",
       "     'isHosted': False,\n",
       "     'pillarId': 'pillar/news',\n",
       "     'pillarName': 'News'}]}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d042afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.append(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
